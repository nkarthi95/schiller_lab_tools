{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c92735",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Adding particles to LB3D checkpoint files\n",
    "=========================================\n",
    "\n",
    "Opening an LB3D checkpoint and adding particles to the current simulation\n",
    "based on particle positions added with fibonacci's method.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from schiller_lab_tools.lb3d import checkpoint_io\n",
    "from schiller_lab_tools.data import particles\n",
    "from schiller_lab_tools.microstructure import interface\n",
    "import copy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82159fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../../data/lb3d\"\n",
    "boxDims = np.array([64, 64, 128])\n",
    "nx, ny, nz = boxDims\n",
    "Q = 19\n",
    "timestep = 10000\n",
    "nprocs = 4\n",
    "Rp = 8\n",
    "Ro = 4\n",
    "npart = 10\n",
    "rhof = 0.7\n",
    "radius_prop = 0.7 # assumes z is the long axis if box size is not cubic\n",
    "\n",
    "gr_out = \"restart\"\n",
    "npart_new = 25\n",
    "## EDIT THIS ONLY ##\n",
    "\n",
    "output_path = f\"{path}/add_particles/npart_{npart_new}\"\n",
    "os.makedirs(output_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a4405d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## READING OLD CHECKPOINTS ##\n",
    "checkparams_files = sorted(glob.glob(f\"{path}/checkparams*{timestep:08d}*.xdr\"))[0]\n",
    "fluid_checkpoint_files = sorted(glob.glob(f\"{path}/checkpoint*{timestep:08d}*.xdr\"))\n",
    "checktopo_files = sorted(glob.glob(f\"{path}/checktopo*{timestep:08d}*.xdr\"))[0]\n",
    "md_checkpoint_files = sorted(glob.glob(f\"{path}/md-checkpoint*{timestep:08d}*.xdr\"))[0]\n",
    "\n",
    "curr_check_params = checkpoint_io.read_checkparams_xdr(checkparams_files)\n",
    "curr_topo = checkpoint_io.read_checktopo_xdr(checktopo_files, nprocs = nprocs)\n",
    "curr_fluid_params = checkpoint_io.read_checkpoint_xdr(fluid_checkpoint_files, nx, ny, nz, curr_topo, Q)\n",
    "curr_md_params = checkpoint_io.read_md_checkpoint_xdr(md_checkpoint_files, use_rotation=True, interaction=\"ladd\", n_spec = 2)\n",
    "print(\"Checkpoints to be copied have been read\")\n",
    "## READING OLD CHECKPOINTS ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817c58b5",
   "metadata": {},
   "source": [
    "# Parameter file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e289f55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PARAMETER CHECKPOINT FILE ##\n",
    "new_check_params = copy.deepcopy(curr_check_params)\n",
    "# new_check_params['g_accn_max'] = 2*(nz - join_cut - other_cut) # Changing boxsize in the z direction to new size\n",
    "print(\"New parameter file generated\")\n",
    "## PARAMETER CHECKPOINT FILE ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503a7399",
   "metadata": {},
   "source": [
    "# Fluid files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5390a4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## FLUID CHECKPOINT FILE ##\n",
    "new_fluid_params = curr_fluid_params.copy()\n",
    "print(\"New fluid checkpoint file generated\")\n",
    "# ## FLUID CHECKPOINT FILE ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea4da6a",
   "metadata": {},
   "source": [
    "# Topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5227e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TOPOLOGY CHECKPOINT FILE ##\n",
    "new_topo = copy.deepcopy(curr_topo)\n",
    "new_topo['cdims'] = [1,1,1]\n",
    "new_topo['all_ccoords'] = [0,0,0]\n",
    "new_topo['nprocs'] = 1\n",
    "print(\"New mpi topology file generated\")\n",
    "## TOPOLOGY CHECKPOINT FILE ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fcff57",
   "metadata": {},
   "source": [
    "# MD Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6e7626",
   "metadata": {},
   "outputs": [],
   "source": [
    "## MD CHECKPOINT FILE ##\n",
    "curr_part_locs = np.array([part['x'] for part in curr_md_params['particles']])\n",
    "Rd = np.linalg.norm(curr_part_locs - np.array([32, 32, 64]), axis = -1).mean()\n",
    "\n",
    "new_md_params = copy.deepcopy(curr_md_params)\n",
    "\n",
    "new_particles = [] \n",
    "n = len(new_md_params[\"particles\"])\n",
    "\n",
    "center = np.array([nx//2, ny//2, nz//2])\n",
    "new_part_locs = particles.fibonacci_sphere(npart_new, Rd, center, jitter = 0.01)\n",
    "reference_dir = np.array([1,0,0])\n",
    "new_part_quaternions = [particles.orientation_to_quarternion(reference_dir, pos - center) for pos in new_part_locs]\n",
    "\n",
    "## adding particles by shifting by nz - cut and particles for new droplet.\n",
    "# Particles are added on top of each other and require equilibration to be pushed apart\n",
    "idx = 0\n",
    "particle_id = 1\n",
    "\n",
    "for i in range(npart):\n",
    "    curr_part = copy.deepcopy(new_md_params[\"particles\"][i])\n",
    "    curr_part[\"uid\"] = particle_id\n",
    "    \n",
    "    curr_part[\"x\"] =  new_part_locs[idx]\n",
    "    # curr_part['q'] = new_part_quaternions[idx]\n",
    "\n",
    "    curr_part[\"v\"]    = [0.0, 0.0, 0.0]\n",
    "    curr_part[\"vnew\"] = [0.0, 0.0, 0.0]\n",
    "\n",
    "    curr_part[\"q\"]    = new_part_quaternions[idx]\n",
    "    curr_part[\"qnew\"] = new_part_quaternions[idx]\n",
    "\n",
    "    curr_part[\"w\"]    = [0.0, 0.0, 0.0]\n",
    "    curr_part[\"wnew\"] = [0.0, 0.0, 0.0]\n",
    "    new_particles.append(curr_part)\n",
    "    particle_id += 1\n",
    "    idx += 1\n",
    "\n",
    "diff_part = npart_new - npart\n",
    "\n",
    "# Copies all properties of existing particles. Substitutes the new particle locations and unique ID's\n",
    "# 1st for loop accounts for if number of particles to be added is larger than number of particles currently present\n",
    "for i in range(diff_part//npart):\n",
    "    for j in range(npart):\n",
    "        curr_part = copy.deepcopy(new_md_params[\"particles\"][j])\n",
    "        curr_part[\"uid\"] = particle_id\n",
    "\n",
    "        curr_part[\"x\"] =  new_part_locs[idx]\n",
    "        # curr_part['q'] = new_part_quaternions[idx]\n",
    "\n",
    "        curr_part[\"v\"]    = [0.0, 0.0, 0.0]\n",
    "        curr_part[\"vnew\"] = [0.0, 0.0, 0.0]\n",
    "\n",
    "        curr_part[\"q\"]    = new_part_quaternions[idx]\n",
    "        curr_part[\"qnew\"] = new_part_quaternions[idx]\n",
    "\n",
    "        curr_part[\"w\"]    = [0.0, 0.0, 0.0]\n",
    "        curr_part[\"wnew\"] = [0.0, 0.0, 0.0]\n",
    "        \n",
    "        new_particles.append(curr_part)\n",
    "        particle_id += 1\n",
    "        idx += 1\n",
    "\n",
    "# 2nd loop accounts for number of particles that is not a clean multiple\n",
    "for j in range(diff_part%npart):\n",
    "    curr_part = copy.deepcopy(new_md_params[\"particles\"][j])\n",
    "    curr_part[\"uid\"] = particle_id\n",
    "\n",
    "    curr_part[\"x\"] =  new_part_locs[idx]\n",
    "    # curr_part['q'] = new_part_quaternions[idx]\n",
    "\n",
    "    curr_part[\"v\"]    = [0.0, 0.0, 0.0]\n",
    "    curr_part[\"vnew\"] = [0.0, 0.0, 0.0]\n",
    "\n",
    "    curr_part[\"q\"]    = new_part_quaternions[idx]\n",
    "    curr_part[\"qnew\"] = new_part_quaternions[idx]\n",
    "\n",
    "    curr_part[\"w\"]    = [0.0, 0.0, 0.0]\n",
    "    curr_part[\"wnew\"] = [0.0, 0.0, 0.0]\n",
    "    new_particles.append(curr_part)\n",
    "    particle_id += 1\n",
    "    idx += 1\n",
    "\n",
    "## mass correction scheme also needs to be adjusted. \n",
    "ladd_data = new_md_params['ladd_data']\n",
    "mass_target = np.array(ladd_data[\"global_mass_target\"])\n",
    "new_ladd_data = copy.deepcopy(ladd_data)\n",
    "\n",
    "## TECHNIQUE 3: Calculating mass of box components after slicing ##\n",
    "particle_masses = 4/3*np.pi*Ro*Ro*Rp*npart_new*rhof\n",
    "new_target_mass = np.array([np.sum(new_fluid_params[..., :Q])/curr_check_params['taubulk_r'], np.sum(new_fluid_params[..., Q:2*Q])/curr_check_params['taubulk_b']])\n",
    "new_target_mass -= particle_masses/4\n",
    "new_ladd_data[\"global_mass_target\"] = new_target_mass\n",
    "## TECHNIQUE 3: Calculating mass of box components after slicing ##\n",
    "\n",
    "\n",
    "new_md_params['particles'] = new_particles\n",
    "new_md_params['ladd_data'] = new_ladd_data\n",
    "print(\"New MD checkpoint file generated\")\n",
    "## MD CHECKPOINT FILE ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320bcda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a 3D plot of the system\n",
    "fig = plt.figure(figsize = (10, 5))\n",
    "\n",
    "# Make data for droplet\n",
    "u = np.linspace(0, 2 * np.pi, 100)\n",
    "v = np.linspace(0, np.pi, 100)\n",
    "droplet_coordinates = np.array([Rd*np.outer(np.cos(u), np.sin(v)),\n",
    "                                Rd*np.outer(np.sin(u), np.sin(v)),\n",
    "                                Rd*np.outer(np.ones(np.size(u)), np.cos(v))])\n",
    "\n",
    "# coordinates shifted by boxDim//2 to account for center of mass location\n",
    "droplet_coordinates += boxDims[:, np.newaxis, np.newaxis]//2\n",
    "\n",
    "ax = fig.add_subplot(121, projection=\"3d\")\n",
    "ax.set_title(\"Old particle locations\")\n",
    "ax.plot_surface(*droplet_coordinates, alpha = 0.3) # Plot the surface\n",
    "ax.scatter(*curr_part_locs.T, color=\"black\")\n",
    "\n",
    "ax = fig.add_subplot(122, projection=\"3d\")\n",
    "ax.set_title(\"New particle locations\")\n",
    "ax.plot_surface(*droplet_coordinates, alpha = 0.3) # Plot the surface\n",
    "ax.scatter(*new_part_locs.T, color=\"black\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab73d799",
   "metadata": {},
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50370941",
   "metadata": {},
   "outputs": [],
   "source": [
    "## OUTPUTTING NEW CHECKPOINTS ##\n",
    "uid = np.random.randint(0, 2**31, 1)[0] # Generating random number of a signed FP32 integer\n",
    "\n",
    "checkparams_file_template = \"checkparams_{0}_t{1:08d}-{2:010d}.xdr\"\n",
    "fluid_checkpoint_file_template = \"checkpoint_{0}_t{1:08d}-{2:010d}_p{3:06d}.xdr\"\n",
    "checktopo_file_template = \"checktopo_{0}_t{1:08d}-{2:010d}.xdr\"\n",
    "md_checkpoint_file_template = \"md-checkpoint_{0}_t{1:08d}-{2:010d}.xdr\"\n",
    "\n",
    "output_params_path = output_path + \"/\" + checkparams_file_template.format(gr_out, timestep, uid)\n",
    "output_fluid_path = output_path + \"/\" + fluid_checkpoint_file_template.format(gr_out, timestep, uid, 0)\n",
    "output_topo_path = output_path + \"/\" + checktopo_file_template.format(gr_out, timestep, uid)\n",
    "output_md_check_path = output_path + \"/\" + md_checkpoint_file_template.format(gr_out, timestep, uid)\n",
    "\n",
    "checkpoint_io.write_checkparams_xdr(output_params_path, new_check_params)\n",
    "checkpoint_io.write_checkpoint_xdr(output_fluid_path, new_fluid_params)\n",
    "checkpoint_io.write_checktopo_xdr(output_topo_path, new_topo)\n",
    "checkpoint_io.write_md_checkpoint_xdr(output_md_check_path, new_md_params[\"particles\"], \n",
    "                                    use_rotation=True, steps_per_lbe_step=1, interaction=\"ladd\",\n",
    "                                    ladd_props=new_md_params['ladd_data'],\n",
    "                                    n_spec=2)\n",
    "\n",
    "print(f\"Checkpoint output successful!. UID:{uid}\")\n",
    "## OUTPUTTING NEW CHECKPOINTS ##"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LB3D",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
