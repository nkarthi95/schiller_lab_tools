{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c92735",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "from lb3d_checkpoint_io import *\n",
    "import copy\n",
    "import os\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82159fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"rectangle_system\"\n",
    "path = \"anisotropic_particle\"\n",
    "nx, ny, nz = [64, 64, 128]\n",
    "Q = 19\n",
    "timestep = 10000\n",
    "nprocs = 4\n",
    "Rp = 8\n",
    "Ro = 4\n",
    "npart = 10\n",
    "rhof = 0.7\n",
    "radius_prop = 0.7 # assumes z is the long axis if box size is not cubic\n",
    "\n",
    "gr_out = \"restart\"\n",
    "npart_new = 25\n",
    "# join_cut = 30\n",
    "# other_cut = 20\n",
    "## EDIT THIS ONLY ##\n",
    "\n",
    "output_path = f\"{path}/add_particles/npart_{npart_new}\"\n",
    "os.makedirs(output_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a4405d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## READING OLD CHECKPOINTS ##\n",
    "checkparams_files = sorted(glob.glob(f\"{path}/checkparams*{timestep:08d}*.xdr\"))[0]\n",
    "fluid_checkpoint_files = sorted(glob.glob(f\"{path}/checkpoint*{timestep:08d}*.xdr\"))\n",
    "checktopo_files = sorted(glob.glob(f\"{path}/checktopo*{timestep:08d}*.xdr\"))[0]\n",
    "md_checkpoint_files = sorted(glob.glob(f\"{path}/md-checkpoint*{timestep:08d}*.xdr\"))[0]\n",
    "\n",
    "curr_check_params = read_checkparams_xdr(checkparams_files)\n",
    "curr_topo = read_checktopo_xdr(checktopo_files, nprocs = nprocs)\n",
    "curr_fluid_params = read_checkpoint_xdr(fluid_checkpoint_files, nx, ny, nz, curr_topo, Q)\n",
    "curr_md_params = read_md_checkpoint_xdr(md_checkpoint_files, use_rotation=True, interaction=\"ladd\", n_spec = 2)\n",
    "print(\"Checkpoints to be copied have been read\")\n",
    "## READING OLD CHECKPOINTS ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817c58b5",
   "metadata": {},
   "source": [
    "# Parameter file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e289f55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PARAMETER CHECKPOINT FILE ##\n",
    "new_check_params = copy.deepcopy(curr_check_params)\n",
    "# new_check_params['g_accn_max'] = 2*(nz - join_cut - other_cut) # Changing boxsize in the z direction to new size\n",
    "print(\"New parameter file generated\")\n",
    "## PARAMETER CHECKPOINT FILE ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503a7399",
   "metadata": {},
   "source": [
    "# Fluid files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5390a4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## FLUID CHECKPOINT FILE ##\n",
    "# new_fluid_params = np.empty((nx, ny, 2*(nz - join_cut - other_cut), 2*Q+4))\n",
    "# l_slc = np.s_[:, :, other_cut:nz-join_cut, :Q] # using array slicing to slice data on the right side of the box to reduce distance between droplets\n",
    "# r_slc = np.s_[:, :, join_cut:nz-other_cut, :Q] # using array slicing to slice data on the right side of the box to reduce distance between droplets\n",
    "# new_fluid_params[..., :Q]    = np.concatenate([curr_fluid_params[l_slc], curr_fluid_params[r_slc]], axis = -2) #concatenating on the z axis for f dist\n",
    "\n",
    "# l_slc = np.s_[:, :, other_cut:nz-join_cut, Q:2*Q] # using array slicing to slice data on the right side of the box to reduce distance between droplets\n",
    "# r_slc = np.s_[:, :, join_cut:nz-other_cut, Q:2*Q] # using array slicing to slice data on the right side of the box to reduce distance between droplets\n",
    "# new_fluid_params[..., Q:2*Q] = np.concatenate([curr_fluid_params[l_slc], curr_fluid_params[r_slc]], axis = -2) #concatenating on the z axis for g dist\n",
    "\n",
    "# new_fluid_params[..., 2*Q:] = 0.0\n",
    "new_fluid_params = curr_fluid_params.copy()\n",
    "print(\"New fluid checkpoint file generated\")\n",
    "# ## FLUID CHECKPOINT FILE ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea4da6a",
   "metadata": {},
   "source": [
    "# Topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5227e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TOPOLOGY CHECKPOINT FILE ##\n",
    "new_topo = copy.deepcopy(curr_topo)\n",
    "new_topo['cdims'] = [1,1,1]\n",
    "new_topo['all_ccoords'] = [0,0,0]\n",
    "new_topo['nprocs'] = 1\n",
    "print(\"New mpi topology file generated\")\n",
    "## TOPOLOGY CHECKPOINT FILE ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fcff57",
   "metadata": {},
   "source": [
    "# MD Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119d4972",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_md_params[\"particles\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6e7626",
   "metadata": {},
   "outputs": [],
   "source": [
    "## MD CHECKPOINT FILE ##\n",
    "new_md_params = copy.deepcopy(curr_md_params)\n",
    "\n",
    "new_particles = [] \n",
    "n = len(new_md_params[\"particles\"])\n",
    "\n",
    "center = (nx//2, ny//2, nz//2)\n",
    "new_part_locs = generate_sphere_surface_points(npart_new, radius = radius_prop*nx/2, center = center, jitter = 0.1)\n",
    "new_part_quaternions = [compute_quaternion_for_sphere_point(p, ref_dir=(1, 0, 0)) for p in new_part_locs]\n",
    "\n",
    "## adding particles by shifting by nz - cut and particles for new droplet.\n",
    "# Particles are added on top of each other and require equilibration to be pushed apart\n",
    "idx = 0\n",
    "particle_id = 1\n",
    "\n",
    "for i in range(npart):\n",
    "    curr_part = copy.deepcopy(new_md_params[\"particles\"][i])\n",
    "    curr_part[\"uid\"] = particle_id\n",
    "    \n",
    "    curr_part[\"x\"] =  new_part_locs[idx]\n",
    "    # curr_part['q'] = new_part_quaternions[idx]\n",
    "\n",
    "    curr_part[\"v\"]    = [0.0, 0.0, 0.0]\n",
    "    curr_part[\"vnew\"] = [0.0, 0.0, 0.0]\n",
    "\n",
    "    curr_part[\"q\"]    = new_part_quaternions[idx]\n",
    "    curr_part[\"qnew\"] = new_part_quaternions[idx]\n",
    "\n",
    "    curr_part[\"w\"]    = [0.0, 0.0, 0.0]\n",
    "    curr_part[\"wnew\"] = [0.0, 0.0, 0.0]\n",
    "    new_particles.append(curr_part)\n",
    "    particle_id += 1\n",
    "    idx += 1\n",
    "\n",
    "diff_part = npart_new - npart\n",
    "\n",
    "# Copies all properties of existing particles. Substitutes the new particle locations and unique ID's\n",
    "# 1st for loop accounts for if number of particles to be added is larger than number of particles currently present\n",
    "for i in range(diff_part//npart):\n",
    "    for j in range(npart):\n",
    "        curr_part = copy.deepcopy(new_md_params[\"particles\"][j])\n",
    "        curr_part[\"uid\"] = particle_id\n",
    "\n",
    "        curr_part[\"x\"] =  new_part_locs[idx]\n",
    "        # curr_part['q'] = new_part_quaternions[idx]\n",
    "\n",
    "        curr_part[\"v\"]    = [0.0, 0.0, 0.0]\n",
    "        curr_part[\"vnew\"] = [0.0, 0.0, 0.0]\n",
    "\n",
    "        curr_part[\"q\"]    = new_part_quaternions[idx]\n",
    "        curr_part[\"qnew\"] = new_part_quaternions[idx]\n",
    "\n",
    "        curr_part[\"w\"]    = [0.0, 0.0, 0.0]\n",
    "        curr_part[\"wnew\"] = [0.0, 0.0, 0.0]\n",
    "        \n",
    "        new_particles.append(curr_part)\n",
    "        particle_id += 1\n",
    "        idx += 1\n",
    "\n",
    "# 2nd loop accounts for number of particles that is not a clean multiple\n",
    "for j in range(diff_part%npart):\n",
    "    curr_part = copy.deepcopy(new_md_params[\"particles\"][j])\n",
    "    curr_part[\"uid\"] = particle_id\n",
    "\n",
    "    curr_part[\"x\"] =  new_part_locs[idx]\n",
    "    # curr_part['q'] = new_part_quaternions[idx]\n",
    "\n",
    "    curr_part[\"v\"]    = [0.0, 0.0, 0.0]\n",
    "    curr_part[\"vnew\"] = [0.0, 0.0, 0.0]\n",
    "\n",
    "    curr_part[\"q\"]    = new_part_quaternions[idx]\n",
    "    curr_part[\"qnew\"] = new_part_quaternions[idx]\n",
    "\n",
    "    curr_part[\"w\"]    = [0.0, 0.0, 0.0]\n",
    "    curr_part[\"wnew\"] = [0.0, 0.0, 0.0]\n",
    "    new_particles.append(curr_part)\n",
    "    particle_id += 1\n",
    "    idx += 1\n",
    "\n",
    "## mass correction scheme also needs to be adjusted. \n",
    "ladd_data = new_md_params['ladd_data']\n",
    "mass_target = np.array(ladd_data[\"global_mass_target\"])\n",
    "new_ladd_data = copy.deepcopy(ladd_data)\n",
    "\n",
    "## TECHNIQUE 3: Calculating mass of box components after slicing ##\n",
    "particle_masses = 4/3*np.pi*Ro*Ro*Rp*npart_new*rhof\n",
    "new_target_mass = np.array([np.sum(new_fluid_params[..., :Q])/curr_check_params['taubulk_r'], np.sum(new_fluid_params[..., Q:2*Q])/curr_check_params['taubulk_b']])\n",
    "new_target_mass -= particle_masses/4\n",
    "new_ladd_data[\"global_mass_target\"] = new_target_mass\n",
    "## TECHNIQUE 3: Calculating mass of box components after slicing ##\n",
    "\n",
    "\n",
    "new_md_params['particles'] = new_particles\n",
    "new_md_params['ladd_data'] = new_ladd_data\n",
    "print(\"New MD checkpoint file generated\")\n",
    "## MD CHECKPOINT FILE ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab73d799",
   "metadata": {},
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50370941",
   "metadata": {},
   "outputs": [],
   "source": [
    "## OUTPUTTING NEW CHECKPOINTS ##\n",
    "uid = np.random.randint(0, 2**31, 1)[0] # Generating random number of a signed FP32 integer\n",
    "\n",
    "checkparams_file_template = \"checkparams_{0}_t{1:08d}-{2:010d}.xdr\"\n",
    "fluid_checkpoint_file_template = \"checkpoint_{0}_t{1:08d}-{2:010d}_p{3:06d}.xdr\"\n",
    "checktopo_file_template = \"checktopo_{0}_t{1:08d}-{2:010d}.xdr\"\n",
    "md_checkpoint_file_template = \"md-checkpoint_{0}_t{1:08d}-{2:010d}.xdr\"\n",
    "\n",
    "output_params_path = output_path + \"/\" + checkparams_file_template.format(gr_out, timestep, uid)\n",
    "output_fluid_path = output_path + \"/\" + fluid_checkpoint_file_template.format(gr_out, timestep, uid, 0)\n",
    "output_topo_path = output_path + \"/\" + checktopo_file_template.format(gr_out, timestep, uid)\n",
    "output_md_check_path = output_path + \"/\" + md_checkpoint_file_template.format(gr_out, timestep, uid)\n",
    "\n",
    "write_checkparams_xdr(output_params_path, new_check_params)\n",
    "write_checkpoint_xdr(output_fluid_path, new_fluid_params, nx, ny, nz)\n",
    "write_checktopo_xdr(output_topo_path, new_topo)\n",
    "write_md_checkpoint_xdr(output_md_check_path, new_md_params[\"particles\"], \n",
    "                        use_rotation=True, steps_per_lbe_step=1, interaction=\"ladd\",\n",
    "                        ladd_props=new_md_params['ladd_data'],\n",
    "                        n_spec=2)\n",
    "\n",
    "print(f\"Checkpoint output successful!. UID:{uid}\")\n",
    "## OUTPUTTING NEW CHECKPOINTS ##"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
