{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_hdf5(filename):\n",
    "    \"\"\"\n",
    "    Reads data from an HDF5 file and returns it as a NumPy array.\n",
    "\n",
    "    The function attempts to read the first dataset in the specified HDF5 file\n",
    "    and converts it into a NumPy array in Fortran order. If the file cannot \n",
    "    be read or an error occurs during the process, the function returns 0.\n",
    "\n",
    "    :param filename: \n",
    "        The absolute or relative path to the HDF5 file to be read.\n",
    "    :type filename: str\n",
    "\n",
    "    :return: \n",
    "        A NumPy array containing the data from the first dataset in the file,\n",
    "        arranged in Fortran order, if the file is successfully read. Returns 0 if \n",
    "        the file cannot be read or an error occurs.\n",
    "    :rtype: numpy.ndarray or int\n",
    "\n",
    "    :note: \n",
    "        - This function assumes the first dataset in the HDF5 file is to be read.\n",
    "        - The dataset is loaded in its native layout, and no reshaping or \n",
    "          additional processing is performed.\n",
    "\n",
    "    :example:\n",
    "        >>> import numpy as np\n",
    "        >>> data = read_hdf5('example.h5')\n",
    "        >>> if isinstance(data, np.ndarray):\n",
    "        >>>     print(\"Data shape:\", data.shape)\n",
    "        >>> else:\n",
    "        >>>     print(\"Failed to read the file.\")\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with h5py.File(filename, 'r') as file:\n",
    "            OutArray = file.get(list(file.keys())[0])\n",
    "            data = np.array(OutArray)\n",
    "    except:\n",
    "        data = 0\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_asc(path, headers=None):\n",
    "    \"\"\"\n",
    "    Reads data from an ASC file and returns it as a pandas DataFrame along with the timestep.\n",
    "\n",
    "    This function processes an ASC file containing simulation data. If no `headers` \n",
    "    are provided, default headers are applied based on the length of the data. \n",
    "    If the file length is 0, a default DataFrame with zero-filled columns is generated. \n",
    "\n",
    "    :param path: \n",
    "        The file path of the ASC file to be read.\n",
    "    :type path: str\n",
    "\n",
    "    :param headers: \n",
    "        Custom column headers for the output DataFrame. If not provided, default \n",
    "        headers are assigned based on the length of the data.\n",
    "    :type headers: list of str, optional\n",
    "\n",
    "    :return: \n",
    "        A tuple containing:\n",
    "        - md_df (pandas.DataFrame): The DataFrame containing the data from the ASC file.\n",
    "        - t (int): The timestep extracted from the file name.\n",
    "    :rtype: tuple\n",
    "\n",
    "    :note: \n",
    "        - The function infers the timestep `t` from the file name by extracting the value after \n",
    "          the last occurrence of 't' in the file name.\n",
    "        - Default headers are:\n",
    "          - `['x', 'y', 'z', 'v_x', 'v_y', 'v_z', 'o_x', 'o_y', 'o_z', 'w_x', 'w_y', 'w_z', 'p_id']` \n",
    "            for files with 13 columns.\n",
    "          - `['x', 'y', 'z', 'v_x', 'v_y', 'v_z', 'o_x', 'o_y', 'o_z', 'w_x', 'w_y', 'w_z', \n",
    "            'Fb_x', 'Fb_y', 'Fb_z', 't_x', 't_y', 't_z', 'p_id']` for files with more than 13 columns.\n",
    "        - If the ASC file is empty, a default DataFrame with zero-filled columns and default headers \n",
    "          is returned.\n",
    "\n",
    "    :example:\n",
    "        >>> df, t = read_asc('data/asc_file_t100.asc')\n",
    "        >>> print(df.head())\n",
    "        >>> print(\"Timestep:\", t)\n",
    "\n",
    "        >>> custom_headers = ['col1', 'col2', 'col3']\n",
    "        >>> df, t = read_asc('data/asc_file_t100.asc', headers=custom_headers)\n",
    "        >>> print(df.head())\n",
    "        >>> print(\"Timestep:\", t)\n",
    "    \"\"\"\n",
    "    md_properties = np.loadtxt(path)\n",
    "    md_properties = md_properties.T\n",
    "    n = md_properties.shape\n",
    "    t = int(path.split('/')[-1].split(\"_\")[-1].split('-')[0].split('t')[-1])\n",
    "\n",
    "    if headers is None:\n",
    "        if n[0] == 0:\n",
    "            headers = np.array(['x', 'y', 'z', 'v_x', 'v_y', 'v_z', 'o_x', 'o_y', 'o_z', \n",
    "                                'w_x', 'w_y', 'w_z', 'p_id'])\n",
    "            d = {h: np.zeros(2) for h in headers}\n",
    "            md_df = pd.DataFrame(d)\n",
    "            return md_df, t\n",
    "        elif n[0] == 13:\n",
    "            headers = np.array(['x', 'y', 'z', 'v_x', 'v_y', 'v_z', 'o_x', 'o_y', 'o_z', \n",
    "                                'w_x', 'w_y', 'w_z', 'p_id'])\n",
    "        elif n[0] > 13:\n",
    "            headers = np.array(['x', 'y', 'z', 'v_x', 'v_y', 'v_z', 'o_x', 'o_y', 'o_z', \n",
    "                                'w_x', 'w_y', 'w_z', 'Fb_x', 'Fb_y', 'Fb_z', 't_x', 't_y', \n",
    "                                't_z', 'p_id'])\n",
    "\n",
    "    d = {header: np.asanyarray(md_properties[i]) if isinstance(md_properties[i], np.ndarray) \n",
    "         else [md_properties[i]] for i, header in enumerate(headers)}\n",
    "\n",
    "    md_df = pd.DataFrame(d)\n",
    "    return md_df, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite_asc_file(path):\n",
    "    \"\"\"\n",
    "    Rewrites an ASC file to ensure it is in a NumPy-parsable format.\n",
    "\n",
    "    This function processes an ASC file to correct formatting issues where values \n",
    "    representing zero are not written in a parsable scientific notation. The corrected \n",
    "    file is saved with the same name, overwriting the original. This ensures compatibility \n",
    "    with NumPy parsing, particularly for files generated by lb3d upon checkpoint restart \n",
    "    or run start.\n",
    "\n",
    "    :param path: \n",
    "        The absolute or relative path of the ASC file to be rewritten.\n",
    "    :type path: str\n",
    "\n",
    "    :return: \n",
    "        Returns 1 to indicate the file has been successfully rewritten.\n",
    "    :rtype: int\n",
    "\n",
    "    :note: \n",
    "        - The function reads the file line by line and checks each numeric value in the file.\n",
    "        - If a value is not in a parsable scientific notation (e.g., missing 'E'), it is corrected.\n",
    "        - The corrected file is written back to the same path, overwriting the original.\n",
    "\n",
    "    :example:\n",
    "        >>> rewrite_asc_file('output/asc_file.asc')\n",
    "        1\n",
    "\n",
    "        After execution, the file `asc_file.asc` will be in the correct format for NumPy parsing.\n",
    "    \"\"\"\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    l = len(lines[0].split())\n",
    "\n",
    "    for i in range(len(lines)):\n",
    "        line = lines[i]\n",
    "        line = line.split()\n",
    "        for j in range(l - 1):\n",
    "            curr = line[j]\n",
    "            split_term = curr.split('E')\n",
    "            if len(split_term) == 1:\n",
    "                correct_term = split_term[0][:-4] + 'E' + split_term[0][-4:]\n",
    "                line[j] = correct_term\n",
    "        lines[i] = ' '.join(line)\n",
    "\n",
    "    with open(path, 'w', encoding='utf-8') as r:\n",
    "        for line in lines:\n",
    "            r.write(line + '\\n')\n",
    "\n",
    "    return 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nkarthiEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
